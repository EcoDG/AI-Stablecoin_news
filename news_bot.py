import os
import requests
from datetime import datetime
import xml.etree.ElementTree as ET
from html import unescape
import re
import time

# í™˜ê²½ ë³€ìˆ˜
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY', 'AIzaSyDzyAdb1L5cJSk4QjIUmJ0PqCrUEOIbfx4')
TELEGRAM_TOKEN = os.getenv('TELEGRAM_TOKEN', '8545984954:AAEZZTPRzn3JMzXedm94WzgY-e6NLiD5D7U')
TELEGRAM_CHAT_ID = os.getenv('TELEGRAM_CHAT_ID', '-1003040543146')

# RSS í”¼ë“œ ì„¤ì •
RSS_FEEDS = {
    "AI": {
        "feeds": [
            "https://techcrunch.com/category/artificial-intelligence/feed/",
            "https://www.theverge.com/ai-artificial-intelligence/rss/index.xml",
        ],
        "keywords": ["ai", "artificial intelligence", "machine learning", "deep learning", 
                    "neural network", "llm", "gpt", "gemini", "claude", "chatgpt", 
                    "openai", "anthropic", "google ai", "generative"]
    },
    "Stablecoin": {
        "feeds": [
            "https://www.coindesk.com/arc/outboundfeeds/rss/",
            "https://cointelegraph.com/rss",
        ],
        "keywords": ["stablecoin", "usdt", "usdc", "tether", "circle", "dai", 
                    "busd", "stable coin", "fiat-backed", "algorithmic"]
    }
}

def translate_title(title, max_retries=3):
    """Geminië¡œ ì œëª©ë§Œ ë²ˆì—­ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
    
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}"
    
    prompt = f"""ë‹¤ìŒ ë‰´ìŠ¤ ì œëª©ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”.
ë°˜ë“œì‹œ ë²ˆì—­ëœ ì œëª©ë§Œ ì¶œë ¥í•˜ê³ , ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ë§í¬ëŠ” ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.

ì œëª©: {title}

ë²ˆì—­:"""
    
    headers = {"Content-Type": "application/json"}
    data = {
        "contents": [{
            "parts": [{"text": prompt}]
        }]
    }
    
    for attempt in range(max_retries):
        try:
            response = requests.post(url, headers=headers, json=data, timeout=45)
            
            if response.status_code == 200:
                result = response.json()
                if 'candidates' in result and len(result['candidates']) > 0:
                    translated = result['candidates'][0]['content']['parts'][0]['text'].strip()
                    
                    # ë¶ˆí•„ìš”í•œ ì ‘ë‘ì‚¬ ì œê±°
                    translated = re.sub(r'^(ë²ˆì—­:|ì œëª©:)\s*', '', translated, flags=re.IGNORECASE)
                    translated = re.sub(r'^["\'](.*)["\']$', r'\1', translated)
                    
                    # ë²ˆì—­ì´ ì œëŒ€ë¡œ ë˜ì—ˆëŠ”ì§€ í™•ì¸ (ì˜ë¬¸ ê·¸ëŒ€ë¡œë©´ ì¬ì‹œë„)
                    if translated and translated != title:
                        return translated
                    else:
                        print(f"      âš ï¸ ë²ˆì—­ ê²°ê³¼ê°€ ì›ë¬¸ê³¼ ë™ì¼, ì¬ì‹œë„ ì¤‘... ({attempt + 1}/{max_retries})")
                        time.sleep(2)
                        continue
            else:
                print(f"      âš ï¸ API ì˜¤ë¥˜ ({response.status_code}), ì¬ì‹œë„ ì¤‘... ({attempt + 1}/{max_retries})")
                time.sleep(2)
                continue
                
        except requests.exceptions.Timeout:
            print(f"      â±ï¸ íƒ€ì„ì•„ì›ƒ, ì¬ì‹œë„ ì¤‘... ({attempt + 1}/{max_retries})")
            time.sleep(2)
            continue
            
        except Exception as e:
            print(f"      âŒ ì˜¤ë¥˜: {e}, ì¬ì‹œë„ ì¤‘... ({attempt + 1}/{max_retries})")
            time.sleep(2)
            continue
    
    # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ì‹œ ì›ë¬¸ ë°˜í™˜
    print(f"      âš ï¸ ë²ˆì—­ ì‹¤íŒ¨ (3íšŒ ì‹œë„), ì›ë¬¸ ì‚¬ìš©")
    return title

def fetch_rss(url):
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        return response.content
    except Exception as e:
        print(f"Error fetching {url.split('/')[2]}: {e}")
        return None

def has_keyword(text, keywords):
    text = text.lower()
    return any(kw.lower() in text for kw in keywords)

def parse_rss(xml_content, keywords=None):
    try:
        root = ET.fromstring(xml_content)
        articles = []
        
        for item in root.findall('.//item'):
            title_elem = item.find('title')
            link_elem = item.find('link')
            
            if title_elem is not None and link_elem is not None:
                title = unescape(title_elem.text or '').strip()
                link = (link_elem.text or '').strip()
                
                if keywords and not has_keyword(title, keywords):
                    continue
                
                if title and link:
                    articles.append({'title': title, 'link': link})
        
        for entry in root.findall('.//{http://www.w3.org/2005/Atom}entry'):
            title_elem = entry.find('{http://www.w3.org/2005/Atom}title')
            link_elem = entry.find('{http://www.w3.org/2005/Atom}link')
            
            if title_elem is not None and link_elem is not None:
                title = unescape(title_elem.text or '').strip()
                link = link_elem.get('href', '')
                
                if keywords and not has_keyword(title, keywords):
                    continue
                
                if title and link:
                    articles.append({'title': title, 'link': link})
        
        return articles[:10]
    except Exception as e:
        print(f"Parse error: {e}")
        return []

def get_news(topic, config, count=3):
    print(f"\n{topic} news collection...")
    
    all_articles = []
    keywords = config.get("keywords", None)
    
    for feed_url in config["feeds"]:
        source = feed_url.split('/')[2].replace('www.', '')
        print(f"  - Fetching {source}")
        
        xml = fetch_rss(feed_url)
        if xml:
            articles = parse_rss(xml, keywords)
            all_articles.extend(articles)
            print(f"    Found: {len(articles)}")
    
    seen = set()
    unique = []
    for article in all_articles:
        if article['link'] not in seen:
            seen.add(article['link'])
            unique.append(article)
    
    print(f"  Total unique: {len(unique)}")
    
    selected = unique[:count]
    
    if not selected:
        return None
    
    # ì œëª© ë²ˆì—­ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
    print(f"  Translating {len(selected)} titles (ìµœëŒ€ 3íšŒ ì¬ì‹œë„)...")
    text = ""
    for i, article in enumerate(selected, 1):
        print(f"    [{i}/{len(selected)}] ë²ˆì—­ ì¤‘...")
        
        # ì œëª©ë§Œ ë²ˆì—­ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
        translated_title = translate_title(article['title'])
        
        source = article['link'].split('/')[2].replace('www.', '')
        
        text += f"### {translated_title}\n"
        text += f"- **ì¶œì²˜**: {source}\n"
        text += f"- **ë§í¬**: {article['link']}\n\n"
    
    return text

def collect_news():
    print("=" * 60)
    print("RSS News Bot with Korean Translation (ì¬ì‹œë„ ë¡œì§)")
    print("=" * 60)
    
    today = datetime.now().strftime("%Yë…„ %mì›” %dì¼")
    
    ai_news = get_news("AI", RSS_FEEDS["AI"], 3)
    stablecoin_news = get_news("Stablecoin", RSS_FEEDS["Stablecoin"], 3)
    
    if not ai_news and not stablecoin_news:
        print("No news found")
        return None
    
    result = f"ğŸ“° **AI & ìŠ¤í…Œì´ë¸”ì½”ì¸ ë‰´ìŠ¤ë ˆí„°**\nğŸ“… {today}\n\n"
    
    if ai_news:
        result += "## ğŸ¤– AI ë‰´ìŠ¤\n\n" + ai_news + "\n"
    
    if stablecoin_news:
        result += "## ğŸ’° ìŠ¤í…Œì´ë¸”ì½”ì¸ ë‰´ìŠ¤\n\n" + stablecoin_news + "\n"
    
    result += "---\nâœ… ì‹¤ì œ RSS í”¼ë“œì—ì„œ ê°€ì ¸ì˜¨ ë‰´ìŠ¤ì…ë‹ˆë‹¤."
    
    return result

def send_telegram(message):
    print("\nSending to Telegram...")
    
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    
    # ë©”ì‹œì§€ê°€ ê¸¸ë©´ ë¶„í• 
    max_length = 4000
    
    if len(message) > max_length:
        parts = []
        current = ""
        
        for line in message.split('\n'):
            if len(current) + len(line) + 1 < max_length:
                current += line + '\n'
            else:
                parts.append(current)
                current = line + '\n'
        
        if current:
            parts.append(current)
        
        for i, part in enumerate(parts):
            data = {
                "chat_id": TELEGRAM_CHAT_ID,
                "text": part,
                "parse_mode": "Markdown",
                "disable_web_page_preview": True
            }
            
            try:
                response = requests.post(url, json=data)
                if response.status_code == 200:
                    print(f"  âœ… Part {i+1}/{len(parts)} sent")
                else:
                    print(f"  Failed part {i+1}: {response.text}")
            except Exception as e:
                print(f"  Error part {i+1}: {e}")
        
        return True
    else:
        data = {
            "chat_id": TELEGRAM_CHAT_ID,
            "text": message,
            "parse_mode": "Markdown",
            "disable_web_page_preview": True
        }
        
        try:
            response = requests.post(url, json=data)
            if response.status_code == 200:
                print("âœ… Sent!")
                return True
            else:
                print(f"Failed: {response.text}")
                return False
        except Exception as e:
            print(f"Error: {e}")
            return False

def main():
    news = collect_news()
    
    if news:
        print("\n" + "=" * 60)
        print("Collection complete!")
        print("=" * 60)
        print("\nPreview:")
        print(news[:400] + "...")
        
        success = send_telegram(news)
        
        if success:
            print("\nğŸ‰ Done!")
        else:
            print("\nFailed to send")
    else:
        print("\nNo news collected")

if __name__ == "__main__":
    main()
